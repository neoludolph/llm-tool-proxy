# Upstream LLM API Configuration
UPSTREAM_URL=http://localhost:11434/v1/chat/completions
UPSTREAM_API_KEY=your-api-key-here

# Model Configuration
DEFAULT_MODEL=llama3.1:8b

# Workspace Configuration
WORKSPACE_ROOT=/app/workspace

# Execution Limits
EXEC_TIMEOUT_MS=8000
EXEC_MAX_BUFFER=1048576

# Security: Blocked commands (regex pattern)
EXEC_BLOCKLIST=rm -rf|shutdown|reboot|mkfs|:\(\)\{:\|:\&\}\;:

# Server Configuration
PORT=11434